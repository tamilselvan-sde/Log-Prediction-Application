{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Simulate real-world application logs\n",
        "sequences = [\n",
        "    [\n",
        "         \"Application started\",\n",
        "       \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "         \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ],\n",
        "    [\n",
        "         \"Application started\",\n",
        "       \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "         \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ],\n",
        "    [\n",
        "         \"Application started\",\n",
        "       \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "         \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Preprocessing function for logs\n",
        "def preprocess_logs(sequence):\n",
        "    preprocessed = []\n",
        "    for log in sequence:\n",
        "        log = re.sub(r'/\\w+-endpoint', '/<ENDPOINT>', log)  # Normalize API endpoints\n",
        "        log = re.sub(r'\\bStep \\d+:', '<STEP>', log)         # Normalize step numbers\n",
        "        log = re.sub(r'timeout|crashed|successfully', '<STATUS>', log)  # Normalize outcomes\n",
        "        preprocessed.append(log)\n",
        "    return preprocessed\n",
        "\n",
        "# Flatten logs and preprocess\n",
        "flattened_logs = [log for sequence in sequences for log in preprocess_logs(sequence)]\n",
        "\n",
        "# Initialize the sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Convert individual logs into embeddings\n",
        "log_vectors = model.encode(flattened_logs)\n",
        "\n",
        "# Calculate similarity matrix\n",
        "similarity_matrix = cosine_similarity(log_vectors)\n",
        "\n",
        "# Assign target values based on similarity\n",
        "threshold = 0.8\n",
        "final_targets = {}\n",
        "current_target = 1\n",
        "\n",
        "for i in range(len(log_vectors)):\n",
        "    if i not in final_targets:\n",
        "        final_targets[i] = current_target\n",
        "        for j in range(i + 1, len(log_vectors)):\n",
        "            if j not in final_targets and similarity_matrix[i][j] > threshold:\n",
        "                final_targets[j] = current_target\n",
        "        current_target += 1\n",
        "\n",
        "# Prepare the DataFrame\n",
        "final_data = {\n",
        "    \"Log\": flattened_logs,\n",
        "    \"Target\": [final_targets[i] for i in range(len(flattened_logs))]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(final_data)\n",
        "\n",
        "# Function to get the target value for a specific row\n",
        "def get_target(row_index):\n",
        "    return df.loc[row_index, \"Target\"]\n",
        "\n",
        "# Example usage\n",
        "print(\"Final DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Get target for row 0\n",
        "row_index = 0\n",
        "print(f\"Target for row {row_index}: {get_target(row_index)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vSAaUvGNA2t",
        "outputId": "dcb26312-7854-406b-8c79-79a87b7415eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final DataFrame:\n",
            "                                          Log  Target\n",
            "0                  <STEP> Application started       1\n",
            "1                       <STEP> User logged in       2\n",
            "2        <STEP> API request made to /endpoint       3\n",
            "3              <STEP> Database query executed       4\n",
            "4            <STEP> Response returned to user       5\n",
            "5                <STEP> User performed action       6\n",
            "6   <STEP> Another API request to /<ENDPOINT>       3\n",
            "7                        <STEP> Cache updated       7\n",
            "8            <STEP> Service <STATUS> occurred       8\n",
            "9                 <STEP> Application <STATUS>       9\n",
            "10                 <STEP> Application started       1\n",
            "11                      <STEP> User logged in       2\n",
            "12       <STEP> API request made to /endpoint       3\n",
            "13             <STEP> Database query executed       4\n",
            "14           <STEP> Response returned to user       5\n",
            "15               <STEP> User performed action       6\n",
            "16  <STEP> Another API request to /<ENDPOINT>       3\n",
            "17                       <STEP> Cache updated       7\n",
            "18           <STEP> Service <STATUS> occurred       8\n",
            "19                <STEP> Application <STATUS>       9\n",
            "20                 <STEP> Application started       1\n",
            "21                      <STEP> User logged in       2\n",
            "22       <STEP> API request made to /endpoint       3\n",
            "23             <STEP> Database query executed       4\n",
            "24           <STEP> Response returned to user       5\n",
            "25               <STEP> User performed action       6\n",
            "26  <STEP> Another API request to /<ENDPOINT>       3\n",
            "27                       <STEP> Cache updated       7\n",
            "28                     <STEP> User logged out       2\n",
            "29          <STEP> Application ended <STATUS>       9\n",
            "Target for row 0: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Simulate real-world application logs\n",
        "sequences = [\n",
        "    [\n",
        "        \"Application started\",\n",
        "        \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "        \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ],\n",
        "    [\n",
        "        \"Application started\",\n",
        "        \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "        \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ],\n",
        "    [\n",
        "        \"Application started\",\n",
        "        \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "        \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"User logged out\",\n",
        "        \"Application ended successfully\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Preprocessing function for logs\n",
        "def preprocess_logs(sequence):\n",
        "    preprocessed = []\n",
        "    for log in sequence:\n",
        "        log = re.sub(r'/\\w+-endpoint', '/<ENDPOINT>', log)  # Normalize API endpoints\n",
        "        log = re.sub(r'timeout|crashed|successfully', '<STATUS>', log)  # Normalize outcomes\n",
        "        preprocessed.append(log)\n",
        "    return preprocessed\n",
        "\n",
        "# Flatten logs and preprocess\n",
        "flattened_logs = [log for sequence in sequences for log in preprocess_logs(sequence)]\n",
        "\n",
        "# Initialize the sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to embed individual words from logs\n",
        "def embed_words(log):\n",
        "    words = log.split()\n",
        "    word_embeddings = model.encode(words)\n",
        "    return word_embeddings\n",
        "\n",
        "# Prepare word-level embeddings\n",
        "word_level_embeddings = []\n",
        "for log in flattened_logs:\n",
        "    word_embeddings = embed_words(log)\n",
        "    word_level_embeddings.append({\"Log\": log, \"Word_Embeddings\": word_embeddings})\n",
        "\n",
        "# Convert individual logs into embeddings\n",
        "log_vectors = model.encode(flattened_logs)\n",
        "\n",
        "# Calculate similarity matrix\n",
        "similarity_matrix = cosine_similarity(log_vectors)\n",
        "\n",
        "# Assign target values based on similarity\n",
        "threshold = 0.8\n",
        "final_targets = {}\n",
        "current_target = 1\n",
        "\n",
        "for i in range(len(log_vectors)):\n",
        "    if i not in final_targets:\n",
        "        final_targets[i] = current_target\n",
        "        for j in range(i + 1, len(log_vectors)):\n",
        "            if j not in final_targets and similarity_matrix[i][j] > threshold:\n",
        "                final_targets[j] = current_target\n",
        "        current_target += 1\n",
        "\n",
        "# Prepare the DataFrame\n",
        "final_data = {\n",
        "    \"Log\": flattened_logs,\n",
        "    \"Target\": [final_targets[i] for i in range(len(flattened_logs))],\n",
        "    \"Word_Embeddings\": [embed_words(log) for log in flattened_logs]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(final_data)\n",
        "\n",
        "# Function to get the target value for a specific row\n",
        "def get_target(row_index):\n",
        "    return df.loc[row_index, \"Target\"]\n",
        "\n",
        "# Example usage\n",
        "print(\"Final DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Get target for row 0\n",
        "row_index = 5\n",
        "print(f\"Target for row {row_index}: {get_target(row_index)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOEM_BiIOlt2",
        "outputId": "180c8fdb-7519-41c7-88ca-749723f9c0ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final DataFrame:\n",
            "                                   Log  Target  \\\n",
            "0                  Application started       1   \n",
            "1                       User logged in       2   \n",
            "2        API request made to /endpoint       3   \n",
            "3              Database query executed       4   \n",
            "4            Response returned to user       5   \n",
            "5                User performed action       6   \n",
            "6   Another API request to /<ENDPOINT>       3   \n",
            "7                        Cache updated       7   \n",
            "8            Service <STATUS> occurred       8   \n",
            "9                 Application <STATUS>       9   \n",
            "10                 Application started       1   \n",
            "11                      User logged in       2   \n",
            "12       API request made to /endpoint       3   \n",
            "13             Database query executed       4   \n",
            "14           Response returned to user       5   \n",
            "15               User performed action       6   \n",
            "16  Another API request to /<ENDPOINT>       3   \n",
            "17                       Cache updated       7   \n",
            "18           Service <STATUS> occurred       8   \n",
            "19                Application <STATUS>       9   \n",
            "20                 Application started       1   \n",
            "21                      User logged in       2   \n",
            "22       API request made to /endpoint       3   \n",
            "23             Database query executed       4   \n",
            "24           Response returned to user       5   \n",
            "25               User performed action       6   \n",
            "26  Another API request to /<ENDPOINT>       3   \n",
            "27                       Cache updated       7   \n",
            "28                     User logged out       2   \n",
            "29          Application ended <STATUS>      10   \n",
            "\n",
            "                                      Word_Embeddings  \n",
            "0   [[-0.033434853, 0.01059796, -0.061904375, -0.1...  \n",
            "1   [[-0.054399997, 0.023594018, -0.032389987, -0....  \n",
            "2   [[-0.1123679, 0.02218953, -0.07871584, 0.01256...  \n",
            "3   [[0.04617131, -0.020743735, -0.092719115, 0.02...  \n",
            "4   [[-0.03762575, 0.07458926, -0.015163289, 0.040...  \n",
            "5   [[-0.054400023, 0.023594009, -0.032390002, -0....  \n",
            "6   [[-0.09228094, -0.08862929, -0.117490694, -0.0...  \n",
            "7   [[-0.024397278, 0.047101755, -0.025165565, -0....  \n",
            "8   [[-0.124083124, 0.020238064, -0.0076299603, -0...  \n",
            "9   [[-0.03343485, 0.010597982, -0.06190429, -0.10...  \n",
            "10  [[-0.033434853, 0.01059796, -0.061904375, -0.1...  \n",
            "11  [[-0.054399997, 0.023594018, -0.032389987, -0....  \n",
            "12  [[-0.1123679, 0.02218953, -0.07871584, 0.01256...  \n",
            "13  [[0.04617131, -0.020743735, -0.092719115, 0.02...  \n",
            "14  [[-0.03762575, 0.07458926, -0.015163289, 0.040...  \n",
            "15  [[-0.054400023, 0.023594009, -0.032390002, -0....  \n",
            "16  [[-0.09228094, -0.08862929, -0.117490694, -0.0...  \n",
            "17  [[-0.024397278, 0.047101755, -0.025165565, -0....  \n",
            "18  [[-0.124083124, 0.020238064, -0.0076299603, -0...  \n",
            "19  [[-0.03343485, 0.010597982, -0.06190429, -0.10...  \n",
            "20  [[-0.033434853, 0.01059796, -0.061904375, -0.1...  \n",
            "21  [[-0.054399997, 0.023594018, -0.032389987, -0....  \n",
            "22  [[-0.1123679, 0.02218953, -0.07871584, 0.01256...  \n",
            "23  [[0.04617131, -0.020743735, -0.092719115, 0.02...  \n",
            "24  [[-0.03762575, 0.07458926, -0.015163289, 0.040...  \n",
            "25  [[-0.054400023, 0.023594009, -0.032390002, -0....  \n",
            "26  [[-0.09228094, -0.08862929, -0.117490694, -0.0...  \n",
            "27  [[-0.024397278, 0.047101755, -0.025165565, -0....  \n",
            "28  [[-0.054399997, 0.023594018, -0.032389987, -0....  \n",
            "29  [[-0.03343485, 0.010597982, -0.06190429, -0.10...  \n",
            "Target for row 5: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rFzHO5QsP7x9",
        "outputId": "c65ba562-931e-4d3c-d588-0d9af4b94983"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Log  Target  \\\n",
              "0            Application started       1   \n",
              "1                 User logged in       2   \n",
              "2  API request made to /endpoint       3   \n",
              "3        Database query executed       4   \n",
              "4      Response returned to user       5   \n",
              "\n",
              "                                     Word_Embeddings  \n",
              "0  [[-0.033434853, 0.01059796, -0.061904375, -0.1...  \n",
              "1  [[-0.054399997, 0.023594018, -0.032389987, -0....  \n",
              "2  [[-0.1123679, 0.02218953, -0.07871584, 0.01256...  \n",
              "3  [[0.04617131, -0.020743735, -0.092719115, 0.02...  \n",
              "4  [[-0.03762575, 0.07458926, -0.015163289, 0.040...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eced657f-67ca-4142-ac48-671221ab1f3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Log</th>\n",
              "      <th>Target</th>\n",
              "      <th>Word_Embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Application started</td>\n",
              "      <td>1</td>\n",
              "      <td>[[-0.033434853, 0.01059796, -0.061904375, -0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>User logged in</td>\n",
              "      <td>2</td>\n",
              "      <td>[[-0.054399997, 0.023594018, -0.032389987, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>API request made to /endpoint</td>\n",
              "      <td>3</td>\n",
              "      <td>[[-0.1123679, 0.02218953, -0.07871584, 0.01256...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Database query executed</td>\n",
              "      <td>4</td>\n",
              "      <td>[[0.04617131, -0.020743735, -0.092719115, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Response returned to user</td>\n",
              "      <td>5</td>\n",
              "      <td>[[-0.03762575, 0.07458926, -0.015163289, 0.040...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eced657f-67ca-4142-ac48-671221ab1f3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eced657f-67ca-4142-ac48-671221ab1f3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eced657f-67ca-4142-ac48-671221ab1f3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c442c2aa-08fa-4fe2-86d3-cc817274bcb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c442c2aa-08fa-4fe2-86d3-cc817274bcb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c442c2aa-08fa-4fe2-86d3-cc817274bcb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Log\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"User logged out\",\n          \"Application <STATUS>\",\n          \"Application started\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word_Embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape log embeddings to add the required time dimension (timesteps = 1)\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])  # Add time dimension\n",
        "y = y.reshape(y.shape[0], y.shape[1])     # Target does not need time dimension\n",
        "\n",
        "# Define the RNN model\n",
        "model_rnn = Sequential([\n",
        "    LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=False),  # input_shape=(timesteps, features)\n",
        "    Dense(X.shape[2], activation='linear')  # Output embedding size\n",
        "])\n",
        "\n",
        "model_rnn.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the RNN\n",
        "model_rnn.fit(X, y, epochs=20, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict the next log embedding for a given input (row 0 in this case)\n",
        "input_row_index = 0\n",
        "input_embedding = X[input_row_index].reshape(1, 1, X.shape[2])  # Add time dimension\n",
        "\n",
        "predicted_embedding = model_rnn.predict(input_embedding)\n",
        "\n",
        "# Find the closest log in the training set for the predicted embedding\n",
        "similarities = cosine_similarity(predicted_embedding, log_embeddings)\n",
        "predicted_index = np.argmax(similarities)\n",
        "\n",
        "# Display the predicted log\n",
        "predicted_log = df.loc[predicted_index, \"Log\"]\n",
        "print(f\"Predicted next log for row {input_row_index}: {predicted_log}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_uRrWX6Q6V0",
        "outputId": "218ea46b-76c9-4ca8-dd7f-1b488465b4d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0280\n",
            "Epoch 2/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.4249e-04 - mae: 0.0230\n",
            "Epoch 3/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7563e-04 - mae: 0.0197 \n",
            "Epoch 4/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5548e-04 - mae: 0.0183 \n",
            "Epoch 5/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1442e-04 - mae: 0.0175 \n",
            "Epoch 6/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8944e-04 - mae: 0.0171 \n",
            "Epoch 7/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1045e-04 - mae: 0.0158  \n",
            "Epoch 8/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6319e-04 - mae: 0.0147 \n",
            "Epoch 9/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5242e-04 - mae: 0.0145 \n",
            "Epoch 10/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2787e-04 - mae: 0.0140 \n",
            "Epoch 11/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0268e-04 - mae: 0.0134 \n",
            "Epoch 12/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1076e-04 - mae: 0.0135 \n",
            "Epoch 13/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8947e-04 - mae: 0.0129  \n",
            "Epoch 14/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3016e-04 - mae: 0.0113 \n",
            "Epoch 15/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3026e-04 - mae: 0.0113 \n",
            "Epoch 16/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8168e-04 - mae: 0.0097 \n",
            "Epoch 17/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0211e-04 - mae: 0.0102 \n",
            "Epoch 18/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5245e-04 - mae: 0.0087 \n",
            "Epoch 19/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7720e-04 - mae: 0.0090 \n",
            "Epoch 20/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0736e-04 - mae: 0.0070 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "Predicted next log for row 0: User logged in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with text input"
      ],
      "metadata": {
        "id": "acVay1n9YzAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Simulate real-world application logs\n",
        "sequences = [\n",
        "    [\n",
        "        \"Application started\",\n",
        "        \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "        \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ],\n",
        "    [\n",
        "        \"Application started\",\n",
        "        \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "        \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"Service timeout occurred\",\n",
        "        \"Application crashed\"\n",
        "    ],\n",
        "    [\n",
        "        \"Application started\",\n",
        "        \"User logged in\",\n",
        "        \"API request made to /endpoint\",\n",
        "        \"Database query executed\",\n",
        "        \"Response returned to user\",\n",
        "        \"User performed action\",\n",
        "        \"Another API request to /other-endpoint\",\n",
        "        \"Cache updated\",\n",
        "        \"User logged out\",\n",
        "        \"Application ended successfully\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Preprocessing function for logs\n",
        "def preprocess_logs(sequence):\n",
        "    preprocessed = []\n",
        "    for log in sequence:\n",
        "        log = re.sub(r'/\\w+-endpoint', '/<ENDPOINT>', log)  # Normalize API endpoints\n",
        "        log = re.sub(r'timeout|crashed|successfully', '<STATUS>', log)  # Normalize outcomes\n",
        "        preprocessed.append(log)\n",
        "    return preprocessed\n",
        "\n",
        "# Flatten logs and preprocess\n",
        "flattened_logs = [log for sequence in sequences for log in preprocess_logs(sequence)]\n",
        "\n",
        "# Initialize the sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Calculate log-level embeddings (mean of word embeddings for each log)\n",
        "def calculate_log_embedding(log):\n",
        "    words = log.split()\n",
        "    word_embeddings = model.encode(words)\n",
        "    return np.mean(word_embeddings, axis=0)  # Take the mean of all word embeddings\n",
        "\n",
        "# Update DataFrame with log-level embeddings\n",
        "log_embeddings = [calculate_log_embedding(log) for log in flattened_logs]\n",
        "\n",
        "# Prepare data for RNN\n",
        "def prepare_sequences(embeddings):\n",
        "    X, y = [], []\n",
        "    for i in range(len(embeddings) - 1):\n",
        "        X.append(embeddings[i])  # Current log embedding\n",
        "        y.append(embeddings[i + 1])  # Next log embedding\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare sequences\n",
        "X, y = prepare_sequences(log_embeddings)\n",
        "\n",
        "# Reshape X to add time dimension (timesteps = 1)\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Define the RNN model with advanced settings\n",
        "model_rnn = Sequential([\n",
        "    LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=False),\n",
        "    Dropout(0.3),  # Add dropout for regularization\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(X.shape[2], activation='linear')  # Output embedding size\n",
        "])\n",
        "\n",
        "# Use the full name for loss function\n",
        "model_rnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the RNN\n",
        "model_rnn.fit(X, y, epochs=50, batch_size=8, verbose=1)  # Increased epochs and smaller batch size for better learning\n",
        "\n",
        "# Save the model\n",
        "model_rnn.save(\"log_prediction_rnn.h5\")\n",
        "print(\"Model saved as log_prediction_rnn.h5\")\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model(\"log_prediction_rnn.h5\")\n",
        "print(\"Model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gvsxonIbwkE",
        "outputId": "9513fb92-2782-4771-84ce-c3c687b29378"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0280\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0256\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4344e-04 - mae: 0.0233\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.5588e-04 - mae: 0.0209 \n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.4476e-04 - mae: 0.0195 \n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.0504e-04 - mae: 0.0191 \n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6588e-04 - mae: 0.0184  \n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.5431e-04 - mae: 0.0183 \n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.3723e-04 - mae: 0.0181 \n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7733e-04 - mae: 0.0171\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2112e-04 - mae: 0.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8811e-04 - mae: 0.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7882e-04 - mae: 0.0171 \n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5232e-04 - mae: 0.0166\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5389e-04 - mae: 0.0166\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.4618e-04 - mae: 0.0164 \n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8810e-04 - mae: 0.0154\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6725e-04 - mae: 0.0150 \n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6401e-04 - mae: 0.0149 \n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2945e-04 - mae: 0.0141\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3832e-04 - mae: 0.0143\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0017e-04 - mae: 0.0133\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.7875e-04 - mae: 0.0128 \n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6544e-04 - mae: 0.0126\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7837e-04 - mae: 0.0128\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4781e-04 - mae: 0.0120\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1314e-04 - mae: 0.0111 \n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1790e-04 - mae: 0.0112\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0301e-04 - mae: 0.0108\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9860e-04 - mae: 0.0107 \n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7198e-04 - mae: 0.0098\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9598e-04 - mae: 0.0105\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4742e-04 - mae: 0.0091 \n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5495e-04 - mae: 0.0092 \n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3409e-04 - mae: 0.0086\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4454e-04 - mae: 0.0089\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4042e-04 - mae: 0.0088\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2457e-04 - mae: 0.0082\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1269e-04 - mae: 0.0078 \n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2077e-04 - mae: 0.0079\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.6428e-05 - mae: 0.0071\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1224e-04 - mae: 0.0074\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7020e-05 - mae: 0.0069 \n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.1740e-05 - mae: 0.0068\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.5579e-05 - mae: 0.0065\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.8367e-05 - mae: 0.0064\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1573e-05 - mae: 0.0062\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.7992e-05 - mae: 0.0061\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.9593e-05 - mae: 0.0051\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.1422e-05 - mae: 0.0051 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as log_prediction_rnn.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the RNN model\n",
        "model_rnn.save('rnn_log_model.h5')\n",
        "\n",
        "# Save log embeddings and flattened logs for later use\n",
        "import pickle\n",
        "with open('log_data.pkl', 'wb') as f:\n",
        "    pickle.dump({'log_embeddings': log_embeddings, 'flattened_logs': flattened_logs}, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geicG6CydrnO",
        "outputId": "9d7189c6-59a5-4d93-f3e2-0837eec67081"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.models import load_model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the saved RNN model\n",
        "model_rnn = load_model('rnn_log_model.h5')\n",
        "\n",
        "# Load log embeddings and flattened logs\n",
        "with open('log_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "log_embeddings = data['log_embeddings']\n",
        "flattened_logs = data['flattened_logs']\n",
        "\n",
        "# Reload the SentenceTransformer model\n",
        "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Function to calculate log embedding\n",
        "def calculate_log_embedding(log):\n",
        "    words = log.split()\n",
        "    word_embeddings = sentence_model.encode(words)\n",
        "    return np.mean(word_embeddings, axis=0)\n",
        "\n",
        "# Function to predict the next log\n",
        "def predict_next_log(input_log):\n",
        "    # Preprocess and calculate the embedding for the input log\n",
        "    input_embedding = calculate_log_embedding(input_log).reshape(1, 1, -1)\n",
        "\n",
        "    # Predict the next log embedding\n",
        "    predicted_embedding = model_rnn.predict(input_embedding)\n",
        "\n",
        "    # Find the closest log in the training set for the predicted embedding\n",
        "    similarities = cosine_similarity(predicted_embedding, log_embeddings)\n",
        "    predicted_index = np.argmax(similarities)\n",
        "\n",
        "    # Return the predicted log\n",
        "    return flattened_logs[predicted_index]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS8b2rL5dwNO",
        "outputId": "0f0ae743-bd69-4510-af4f-3c5d92d9782f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "input_log = \"User performed action\"\n",
        "predicted_log = predict_next_log(input_log)\n",
        "print(f\"Predicted next log for input '{input_log}': {predicted_log}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cNnK74Ld0Bj",
        "outputId": "ee85dac5-24d3-4b52-a6cf-8e419fd842e3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted next log for input 'User performed action': Another API request to /<ENDPOINT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lrt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i_6bnWjfysq",
        "outputId": "85a6728b-2ed1-4193-dd99-ee36bdf40563"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8748\n",
            "drwxr-xr-x 1 root root    4096 Jan 24 14:22 sample_data\n",
            "-rw-r--r-- 1 root root 8901096 Jan 28 10:30 rnn_log_model.h5\n",
            "-rw-r--r-- 1 root root   47716 Jan 28 10:30 log_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_kyErkkfzkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}